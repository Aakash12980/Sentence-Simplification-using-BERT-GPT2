# Leveraging Bert-to-Bert Model for Sentence Simplification in Wikipedia Dataset

The project is based on EncoderDecoderModel from Huggingface and uses bert-base-cased pretrained model for encoder as well as decoder. 

For GPT-2 as Decoder please select gpt2 branch. In this branch, the same model is use but using Bert-to-GPT2 pretrained model.
